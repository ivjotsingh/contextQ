# ContextQ

> **Production-Grade Document Q&A with Intelligent RAG** â€” A sophisticated retrieval-augmented generation system featuring smart query expansion, streaming responses, and transparent source attribution. Built for performance, scalability, and reliability.

![Python](https://img.shields.io/badge/Python-3.11+-blue?style=flat-square&logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-green?style=flat-square&logo=fastapi)
![React](https://img.shields.io/badge/React-18+-61DAFB?style=flat-square&logo=react)
![TypeScript](https://img.shields.io/badge/TypeScript-5+-3178C6?style=flat-square&logo=typescript)
![License](https://img.shields.io/badge/License-MIT-yellow?style=flat-square)

---

## ğŸ† What Makes ContextQ Special

ContextQ isn't just another RAG demo â€” it's a **production-ready**, **enterprise-grade** system demonstrating best practices in modern AI application development:

### ğŸ¯ Intelligent Query Routing
- **Automatic query analysis** â€” Distinguishes greetings, meta-questions, and document queries
- **Fast-path optimization** â€” Skip LLM analysis for simple queries
- **Query expansion for context-dependent questions** â€” Follow-ups like "now?" automatically expand to full queries
- **Document-aware queries** â€” System knows actual filenames and references them precisely

### ğŸš€ Production-Grade Architecture
- **Clean Architecture** â€” Feature modules, dependency injection, standardized responses
- **Dockerized deployment** â€” Multi-stage build for optimized container images
- **Pre-commit hooks** â€” Automated linting (Ruff) and testing before every commit
- **Request tracing** â€” Every request gets a unique ID tracked across all logs
- **Graceful degradation** â€” Chat works even if persistence fails
- **LRU-cached singletons** â€” Prevents memory leaks from repeated dependency instantiation
- **Rate limiting** â€” Per-minute and per-hour limits protect against cost overruns
- **Health checks** â€” Qdrant and Firestore connectivity monitoring
- **Lifespan management** â€” Proper async resource initialization and cleanup

### ğŸ’¡ Sophisticated RAG Pipeline
- **Dynamic relevance thresholding** â€” Configurable similarity scores filter low-quality matches
- **Session-based document scoping** â€” Isolates documents per browser session
- **Filename-aware embeddings** â€” Queries like "show me turnus.pdf" actually work
- **Embedding cache** â€” In-memory LRU cache reduces API calls and costs
- **Chunk deduplication** â€” Prevents redundant context in retrieval
- **Source transparency** â€” Every answer includes  passages with relevance scores

### ğŸ¨ Premium User Experience
- **Real-time streaming** â€” SSE streaming with word-by-word updates
- **Progress tracking** â€” Upload progress with XMLHttpRequest
- **Expandable sources** â€” Click to see full context passages
- **Source grouping** â€” "X sources from Y documents" clarity
- **Session persistence** â€” Documents and chats survive page refresh
- **Modern UI** â€” Glassmorphism, dark mode, smooth animations

### ğŸ“Š Enterprise-Ready Features
- **Duplicate detection** â€” SHA-256 content hashing prevents re-processing
- **Path traversal protection** â€” Filename sanitization prevents directory escape attacks
- **Prompt injection protection** â€” System prompts ignore malicious instructions in document content
- **Table extraction** â€” DOCX tables preserved correctly
- **Async/await throughout** â€” Non-blocking I/O for scalability
- **Structured logging** â€” Production-ready observability
- **Type safety** â€” Pydantic models, TypeScript strict mode
- **Error boundaries** â€” React error boundaries prevent UI crashes

---

## ğŸ‰ Cost-Effective Free Tier

Run the entire stack for **free** during development:

| Service | Free Tier | Purpose |
|---------|-----------|---------|
| **Voyage AI** | 200M tokens | Document embeddings (voyage-3-lite, 512d) |
| **Qdrant Cloud** | 1GB storage | Vector database for semantic search |
| **Firebase** | Firestore free tier | Chat history and session persistence |
| **Claude API** | Pay-as-you-go | Answer generation |

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            ContextQ System                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  React Frontend    â”‚ â”€â”€â”€â”€â–¶  â”‚       FastAPI Backend                 â”‚   â”‚
â”‚  â”‚  (TypeScript)      â”‚        â”‚                                       â”‚   â”‚
â”‚  â”‚                    â”‚        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â€¢ Drag-drop       â”‚        â”‚  â”‚  Query Router (Intelligent)     â”‚  â”‚   â”‚
â”‚  â”‚    upload          â”‚        â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚   â”‚
â”‚  â”‚  â€¢ Streaming       â”‚        â”‚  â”‚  â€¢ Fast-path for greetings      â”‚  â”‚   â”‚
â”‚  â”‚    chat UI         â”‚        â”‚  â”‚  â€¢ Query expansion             â”‚  â”‚   â”‚
â”‚  â”‚  â€¢ Source cards    â”‚        â”‚  â”‚  â€¢ Document context injection   â”‚  â”‚   â”‚
â”‚  â”‚  â€¢ Progress        â”‚        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚    tracking        â”‚        â”‚                                       â”‚   â”‚
â”‚  â”‚  â€¢ Session         â”‚        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚    management      â”‚        â”‚  â”‚  RAG Pipeline                   â”‚  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚   â”‚
â”‚                                â”‚  â”‚  â€¢ Voyage AI embeddings         â”‚  â”‚   â”‚
â”‚                                â”‚  â”‚  â€¢ Qdrant vector search         â”‚  â”‚   â”‚
â”‚                                â”‚  â”‚  â€¢ Relevance filtering          â”‚  â”‚   â”‚
â”‚                                â”‚  â”‚  â€¢ Claude generation            â”‚  â”‚   â”‚
â”‚                                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                                â”‚                                       â”‚   â”‚
â”‚                                â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚                                â”‚  â”‚  Document Processor             â”‚  â”‚   â”‚
â”‚                                â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚   â”‚
â”‚                                â”‚  â”‚  â€¢ PDF/DOCX/TXT parsing         â”‚  â”‚   â”‚
â”‚                                â”‚  â”‚  â€¢ Table extraction             â”‚  â”‚   â”‚
â”‚                                â”‚  â”‚  â€¢ Smart chunking (overlapping) â”‚  â”‚   â”‚
â”‚                                â”‚  â”‚  â€¢ Duplicate detection (SHA256) â”‚  â”‚   â”‚
â”‚                                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                             â”‚                              â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚                 â”‚                           â”‚                       â”‚      â”‚
â”‚                 â–¼                           â–¼                       â–¼      â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚        â”‚ Qdrant Cloud â”‚            â”‚   Firebase   â”‚       â”‚   Claude   â”‚  â”‚
â”‚        â”‚              â”‚            â”‚              â”‚       â”‚     +      â”‚  â”‚
â”‚        â”‚ â€¢ Vectors    â”‚            â”‚ â€¢ Chats      â”‚       â”‚  Voyage AI â”‚  â”‚
â”‚        â”‚ â€¢ Metadata   â”‚            â”‚ â€¢ Sessions   â”‚       â”‚            â”‚  â”‚
â”‚        â”‚ â€¢ Filtering  â”‚            â”‚ â€¢ History    â”‚       â”‚            â”‚  â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Request Flow: Document Query

```
1. User Query: "What are the main risks in the report?"
       â”‚
       â–¼
2. Query Analysis (Claude)
   â†’ skip_rag=false, expanded_query="What are the main risks in the report?"
       â”‚
       â–¼
3. Fetch Session Documents
   â†’ [report.pdf, summary.docx]
       â”‚
       â–¼
4. Embed Query (Voyage AI)
   â†’ "Document: report.pdf\n\nWhat are the main risks..."
       â”‚
       â–¼
5. Vector Search (Qdrant)
   â†’ Top 5 chunks, relevance > 0.34
       â”‚
       â–¼
6. Filter by Relevance
   â†’ 3 chunks pass threshold
       â”‚
       â–¼
7. Generate Answer (Claude, SSE streaming)
   â†’ "Based on the provided documents, the main risks are..."
       â”‚
       â–¼
8. Return with Sources
   â†’ Full answer + 3 source cards with passages
```

---

## ğŸ§© Key Features Breakdown

### Document Processing Pipeline

| Feature | Implementation | Why It Matters |
|---------|----------------|----------------|
| **Multi-format support** | PyPDF2, python-docx, built-in text | PDF, DOCX, TXT all supported |
| **Table extraction** | DOCX table parsing to Markdown | Preserves structured data |
| **Duplicate detection** | SHA-256 content hashing | Prevents wasting embedding tokens |
| **Smart chunking** | Recursive splitting at sentence boundaries | Better semantic coherence |
| **Overlapping chunks** | 1500 chars, 200 overlap (~13%) | Prevents context loss at boundaries |
| **Filename in embeddings** | `"Document: {filename}\n\n{content}"` | Enables filename-based queries |

### Intelligent Query Routing

```python
# Fast Path (50ms)
"hi" â†’ No LLM call â†’ Standard greeting

# Meta Query (500ms)
"what can you do?" â†’ LLM analysis â†’ skip_rag=true â†’ Capabilities response

# Single Document Query (2s)
"summarize this doc" â†’ LLM analysis â†’ RAG pipeline

# Multi-Document Query (3s)
"compare resume.pdf and job description.pdf"
  â†’ LLM analysis 
  â†’ expanded_query="Comparison of content between resume.pdf and job description.pdf"
  â†’ RAG pipeline
```

### Streaming Response System

- **Server-Sent Events (SSE)** â€” Real-time word-by-word streaming
- **Source-first delivery** â€” Sources appear before answer starts
- **Graceful completion** â€” `done` event signals end
- **Error handling** â€” Network errors don't crash the UI
- **Cancellation support** â€” Abort ongoing requests

### Session Architecture

| Identifier | Scope | Storage | Purpose |
|------------|-------|---------|---------|
| `session_id` | Browser | Cookie | Document isolation per browser |
| `chat_id` | Conversation | Firestore | Multiple chats per session |
| `doc_id` | Document | Qdrant | Unique document identifier |

**Design rationale**: One browser can have multiple conversations, each accessing the same set of uploaded documents.

---

## ğŸ› ï¸ Tech Stack Deep Dive

### Backend

| Component | Choice | Rationale |
|-----------|--------|-----------|
| **Python 3.11** | Latest stable | Union types native, modern async support |
| **FastAPI 0.115** | Modern async framework | Native async, auto OpenAPI docs, Pydantic v2 |
| **uv** | Package manager | 10-100x faster than pip, deterministic installs |
| **Ruff** | Linting | Rust-based, 10-100x faster than pylint/flake8 |
| **pytest** | Testing | Industry standard, rich plugin ecosystem |

### Frontend

| Component | Choice | Rationale |
|-----------|--------|-----------|
| **React 18** | UI framework | Concurrent rendering, best ecosystem |
| **TypeScript 5** | Type safety | Catch errors at compile time |
| **Vite** | Build tool | Instant HMR, esbuild speed |
| **Tailwind CSS** | Styling | Utility-first, no CSS naming conflicts |
| **Lucide React** | Icons | Tree-shakeable, modern design |

### AI Services

| Service | Model | Purpose | Performance |
|---------|-------|---------|-------------|
| **Voyage AI** | voyage-3-lite (512d) | Embeddings | 200M free tokens, SOTA retrieval |
| **Claude** | Sonnet 4 | Generation | Superior reasoning, context following |

**Why Voyage over OpenAI?** 
- âœ… Free 200M tokens (vs OpenAI's paid-only)
- âœ… Optimized for RAG use cases with efficient 512d vectors

**Why Claude over GPT?**
- âœ… Better instruction following
- âœ… Lower hallucination rate
- âœ… Superior at citing sources accurately

---

## ğŸ“ Production Engineering Highlights

### Dependency Injection with LRU Caching

```python
# âŒ Memory leak - creates new instance per request
def get_vector_store():
    return VectorStoreService()

# âœ… Singleton pattern - one instance app-wide
@lru_cache(maxsize=1)
def get_vector_store():
    return VectorStoreService()
```

**Impact**: Prevents memory leaks from instantiating expensive services (Qdrant clients, embedding models) per request.

### Request Tracing

Every request gets a unique 8-char ID:

```python
request_id = str(uuid.uuid4())[:8]
logger.info("[%s] Processing query: %s", request_id, question[:100])
# ... later ...
logger.error("[%s] RAG pipeline failed: %s", request_id, error)
```

**Impact**: Debug production issues by grepping logs for `[abc12345]`.

### Graceful Degradation

```python
try:
    await firestore.save_message(chat_id, message)
except Exception as e:
    logger.warning("Failed to save to Firestore: %s", e)
    # Chat continues working without persistence
```

**Impact**: Chat remains functional even if Firebase is down.

### Rate Limiting (Sliding Window)

```python
# Per-minute: Burst protection
# Per-hour: Cost control
RateLimitConfig(
    requests_per_minute=20,
    requests_per_hour=200,
)
```

**Impact**: Prevents API cost explosions from bugs or abuse.

---

## ğŸ§ª Testing Strategy

```bash
# Run tests
uv run pytest -v

# With coverage
uv run pytest --cov=. --cov-report=html
```

**Current Coverage**: ~40%

Covered areas:
- âœ… Chunking logic (overlapping, sentence boundaries)
- âœ… Document parsing (PDF, DOCX, TXT)
- âœ… Duplicate detection (hash validation)

*Higher coverage would add integration tests for Qdrant/Firebase/Claude (requires mocking or paid test instances).*

---

## ğŸ“‚ Project Structure (Clean Architecture)

```
backend/
â”œâ”€â”€ main.py                      # FastAPI app, CORS, lifespan
â”œâ”€â”€ config.py                    # Pydantic settings with env vars
â”œâ”€â”€ dependencies.py              # DI with LRU-cached singletons
â”œâ”€â”€ responses.py                 # Standardized ResponseCode enum
â”œâ”€â”€ router.py                    # Route aggregator
â”‚
â”œâ”€â”€ apps/                        # Feature modules (vertical slices)
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â”‚   â”œâ”€â”€ stream_response.py    # SSE streaming, query routing
â”‚   â”‚   â”‚   â””â”€â”€ get_chat_history.py   # Conversation history
â”‚   â”‚   â”œâ”€â”€ chat_history.py           # Persistence manager
â”‚   â”‚   â”œâ”€â”€ session_helpers.py         # Cookie management
â”‚   â”‚   â””â”€â”€ routes.py
â”‚   â”‚
â”‚   â”œâ”€â”€ documents/
â”‚   â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â”‚   â”œâ”€â”€ upload_document.py    # Parse, chunk, embed, store
â”‚   â”‚   â”‚   â”œâ”€â”€ list_documents.py     # Session-scoped listing
â”‚   â”‚   â”‚   â””â”€â”€ delete_document.py    # Qdrant + metadata cleanup
â”‚   â”‚   â””â”€â”€ routes.py
â”‚   â”‚
â”‚   â””â”€â”€ health/
â”‚       â””â”€â”€ handlers/check_health.py  # Qdrant + Firebase health
â”‚
â”œâ”€â”€ services/                    # Reusable business logic
â”‚   â”œâ”€â”€ document.py              # PDF/DOCX/TXT parsing + tables
â”‚   â”œâ”€â”€ chunker.py               # Recursive text splitting
â”‚   â”œâ”€â”€ embeddings.py            # Voyage AI with retry logic
â”‚   â”œâ”€â”€ vector_store.py          # Qdrant CRUD + search
â”‚   â””â”€â”€ rag.py                   # Pure retrieval + generation
â”‚
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ service.py               # LLM abstraction (Claude)
â”‚   â””â”€â”€ prompts/                 # Engineered system prompts
â”‚       â”œâ”€â”€ assistant.py         # General assistant capabilities
â”‚       â”œâ”€â”€ document_qa.py       # RAG-specific instructions
â”‚       â””â”€â”€ query_analysis.py    # Query routing (skip_rag, expansion)
â”‚
â”œâ”€â”€ middleware/
â”‚   â””â”€â”€ rate_limit.py            # Sliding window rate limiter
â”‚
â”œâ”€â”€ db/
â”‚   â””â”€â”€ firestore.py             # Firebase operations
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_chunker.py          # Chunking edge cases
    â””â”€â”€ test_document.py         # Parsing validation
```

**Design Principles**:
- **Feature modules in `/apps`** â€” Each feature is self-contained
- **Reusable services in `/services`** â€” Domain-agnostic logic
- **Clean separation** â€” Handlers call services, services don't know HTTP

---

## ğŸ¯ Design Decisions

### Why This Chunking Strategy?

```python
CHUNK_SIZE = 1500      # ~375 tokens at 4 chars/token
CHUNK_OVERLAP = 200    # ~13% overlap
```

**Rationale**:
1. **Voyage-3-lite optimized for 300-500 tokens** â€” Larger chunks would exceed model sweet spot
2. **Overlap preserves context** â€” Prevents information loss at chunk boundaries
3. **Sentence-aware breaking** â€” Chunks don't split mid-sentence (when possible)
4. **Industry standard** â€” Research shows 10-20% overlap optimal for retrieval

### Why Firebase for Chat History?

| Alternative | Cons | Firebase Pros |
|-------------|------|---------------|
| **PostgreSQL** | Infrastructure overhead, need vector extension | Serverless, free tier, real-time |
| **Redis** | Volatile, need backup strategy | Persistent, indexed queries |
| **Qdrant** | Not optimized for transactional data | Purpose-built for chat |

**Winner**: Firebase Firestore â€” Serverless, persistent, free tier, composite indexes.

### Why Cookie-Based Sessions?

| Alternative | Cons | Cookie Pros |
|-------------|------|-------------|
| **JWT tokens** | Requires auth system, expiration management | Automatic browser handling |
| **URL params** | Insecure, breaks on copy/paste | httpOnly, secure flags |
| **Local storage** | Per-origin, cross-tab sync issues | Server-controlled |

**Winner**: Session cookies â€” Simple, secure, no frontend state management.

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **Node 18+** (for frontend)
- **API Keys**: [Voyage AI](https://www.voyageai.com/), [Anthropic Claude](https://www.anthropic.com/)
- **Firebase Project**: [Create free project](https://console.firebase.google.com/)
- **Qdrant Cloud**: [Free 1GB cluster](https://qdrant.tech/)

### Setup (5 minutes)

```bash
# 1. Clone
git clone https://github.com/ivjotsingh/contextQ.git
cd contextQ

# 2. Backend setup
cd backend
cp .env.example .env
# Edit .env with your API keys

# Install dependencies
uv sync

# Run backend
uv run uvicorn main:app --reload
# â†’ http://localhost:8000

# 3. Frontend setup (new terminal)
cd ../frontend
npm install
npm run dev
# â†’ http://localhost:5173
```

### Environment Variables

```bash
# .env file
ANTHROPIC_API_KEY=sk-ant-...
VOYAGE_API_KEY=pa-...

# Firebase (from firebase console â†’ project settings)
FIREBASE_PROJECT_ID=your-project-id
FIREBASE_PRIVATE_KEY_ID=abc123...
FIREBASE_PRIVATE_KEY="-----BEGIN PRIVATE KEY-----\n..."
FIREBASE_CLIENT_EMAIL=firebase-adminsdk-...@....iam.gserviceaccount.com
FIREBASE_CLIENT_ID=123456789...

# Qdrant Cloud
QDRANT_URL=https://your-cluster.qdrant.io
QDRANT_API_KEY=your-api-key
```

### Firebase Index Setup

Create composite index in [Firestore Console](https://console.firebase.google.com/):

| Collection | Fields (in order) | Type |
|------------|-------------------|------|
| `chats` | `session_id` | Ascending |
| `chats` | `last_activity` | Descending |
| `chats` | `__name__` | Descending |

---

## ğŸ“š API Documentation

Auto-generated OpenAPI docs at `/docs` when running backend.

### Example: Stream Chat Response

```bash
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -H "Cookie: session_id=$SESSION_ID" \
  -d '{
    "question": "What are the key findings?",
    "chat_id": "abc-123",
    "doc_ids": null
  }'
```

Response (SSE stream):
```
data: {"type":"sources","sources":[{"text":"...","filename":"report.pdf","relevance_score":0.89}]}

data: {"type":"content","content":"Based"}
data: {"type":"content","content":" on"}
data: {"type":"content","content":" the"}
...
data: {"type":"done"}
```

---

## ğŸ… Production Deployment Checklist

- [ ] Set `CORS_ORIGINS` to your frontend domain
- [ ] Enable Firebase security rules  
- [ ] Set up Qdrant authentication
- [ ] Configure rate limits for production scale
- [ ] Set `secure=True` for session cookies (HTTPS only)
- [ ] Add monitoring (Sentry, Datadog, etc.)
- [ ] Set up backup for Firestore
- [ ] Configure auto-scaling for FastAPI workers
- [ ] Add CDN for frontend static files
- [ ] Enable Qdrant backups

---

## ğŸ”® Future Improvements

### Out of Scope for This Project

**RAG & Retrieval Enhancements:**
- **Hybrid search** â€” Combine BM25 (keyword) + vector (semantic) for best results
- **Semantic chunking** â€” Chunk by meaning instead of fixed size
- **Multi-modal support** â€” Extract and search images/charts from PDFs
- **Citation markers** â€” LLM outputs [1], [2] references linked to source chunks

**Production Infrastructure:**
- **Caching layer** â€” Redis for embeddings, responses, and hot documents
- **Cost tracking** â€” Real-time API cost monitoring with budget alerts
- **Latency optimizations** â€” Parallel embedding, response streaming from first token

**Security & Compliance:**
- **Authentication** â€” User accounts with JWT, role-based access control
- **Document-level permissions** â€” Multi-tenant isolation, access control lists
- **Output validation** â€” PII detection, toxic content filtering
- **GDPR compliance** â€” Right to delete, data export

**User Experience:**
- **OCR support** â€” Scanned PDFs via pytesseract or AWS Textract
- **Multi-language** â€” i18n for global users
- **Export functionality** â€” Chat history to PDF/Markdown
- **Document annotations** â€” Highlight and note passages
- **Voice input/output** â€” Speech-to-text queries, text-to-speech answers
- **Collaborative Q&A** â€” Multiple users asking about shared documents

**Advanced Features:**
- **Document versioning** â€” Track changes, compare versions
- **Usage analytics** â€” User behavior insights, popular queries
- **Smart suggestions** â€” Recommend related questions based on context

---

## ğŸ¤ Acknowledgments

Built using industry-best practices from:
- [FastAPI Best Practices](https://github.com/zhanymkanov/fastapi-best-practices)
- [Qdrant RAG Patterns](https://qdrant.tech/documentation/tutorials/rag/)
- [React TypeScript Patterns](https://react-typescript-cheatsheet.netlify.app/)

---

## ğŸ“„ License

MIT â€” See [LICENSE](LICENSE) for details.

---

**Built with â¤ï¸ for production-grade AI applications**

[View on GitHub](https://github.com/ivjotsingh/contextQ/tree/contextQ)
